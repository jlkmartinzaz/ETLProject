\documentclass[12pt,a4paper]{article}

\usepackage{fontspec} % Requerido para LuaLaTeX
\usepackage{polyglossia}
\setmainlanguage{spanish}
\usepackage[colorlinks=true, linkcolor=black, urlcolor=blue, citecolor=black]{hyperref}
\setmainfont{TeX Gyre Termes} % O cualquier fuente que tengas
\usepackage[margin=2.5cm]{geometry}
\usepackage{hyperref}

\title{Documentación del Proyecto ETL con CSV de Nvidia}
\author{Tu Nombre}
\date{\today}

\begin{document}
	
	\maketitle
	\tableofcontents
	\newpage
	
	\section{Introducción}
	El presente proyecto consiste en un flujo ETL (\textbf{Extract, Transform, Load}) para procesar datos históricos de acciones de Nvidia. El objetivo principal fue leer un archivo CSV, limpiar y transformar los datos, y finalmente generar un nuevo CSV listo para análisis posteriores.
	
	\section{Dataset de Nvidia}
	El proyecto utiliza un conjunto de datos históricos de las acciones de Nvidia.\footnote{\url{https://www.kaggle.com/datasets/ranugadisansagamage/nividia-stock}}
	
	\subsection{Descripción}
	Este dataset contiene información diaria de las acciones de Nvidia desde 1999 hasta 2024. Es útil para análisis financieros, predicciones de precios y estudios de tendencias del mercado.
	
	\subsection{Columnas del dataset}
	\begin{itemize}
		\item \textbf{Date}: Fecha de la transacción.
		\item \textbf{Open}: Precio de apertura de la acción.
		\item \textbf{High}: Precio máximo alcanzado durante el día.
		\item \textbf{Low}: Precio mínimo alcanzado durante el día.
		\item \textbf{Close}: Precio de cierre de la acción.
		\item \textbf{Adj Close}: Precio de cierre ajustado por dividendos y splits.
		\item \textbf{Volume}: Número de acciones negociadas.
	\end{itemize}
	
	\subsection{Ejemplo de filas}
	\begin{center}
		\begin{tabular}{|c|c|c|c|c|c|c|}
			\hline
			Date & Open & High & Low & Close & Adj Close & Volume \\
			\hline
			2024-12-31 & 150.00 & 155.00 & 149.00 & 153.00 & 153.00 & 200000 \\
			2024-12-30 & 148.50 & 151.00 & 147.00 & 150.50 & 150.50 & 180000 \\
			\hline
		\end{tabular}
	\end{center}
	
	\section{Herramientas utilizadas}
	\begin{itemize}
		\item \textbf{Python 3.12} para la implementación del flujo ETL.
		\item \textbf{Pandas} para manipulación y transformación de datos.
		\item \textbf{Vim} como editor de código.
		\item \textbf{Git y GitHub} para control de versiones y gestión de ramas (\texttt{main}, \texttt{develop}, \texttt{release}).
		\item \textbf{ChatGPT} para apoyo en la programación, depuración de errores y recomendaciones de flujo ETL.
	\end{itemize}
	
	\section{Estructura del proyecto}
	\begin{itemize}
		\item Config/config.py
		\item Extract/extractor.py
		\item Extract/Files/Nvidia.csv
		\item Transform/transformer.py
		\item Load/loader.py
		\item main.py
	\end{itemize}
	
	\section{Flujo ETL}
	\subsection{Extract}
	Se implementó la clase \texttt{Extractor} en \texttt{Extract/extractor.py}, que lee el CSV original (\texttt{Nvidia.csv}) y retorna un DataFrame de Pandas.
	
	\subsection{Transform}
	La clase \texttt{Transformer} en \texttt{Transform/transformer.py} realiza:
	\begin{itemize}
		\item Conversión de la columna \texttt{Date} a tipo \texttt{datetime64[ns]}.
		\item Ordenación por fecha.
		\item Relleno de valores nulos.
		\item Cálculo de nuevas columnas:
		\begin{itemize}
			\item \texttt{Daily Change} = \texttt{Close - Open}
			\item \texttt{Percent Change} = \(\frac{Close - Open}{Open} \times 100\)
		\end{itemize}
	\end{itemize}
	
	\subsection{Load}
	La clase \texttt{Loader} en \texttt{Load/loader.py} guarda el DataFrame final en un nuevo CSV llamado \texttt{Nvidia\_clean.csv} en la carpeta \texttt{Extract/Files/}.
	
	\section{Prompts de ChatGPT más relevantes}
	\begin{itemize}
		\item Depurar errores de rutas y lectura de CSV.
		\item Ajustar transformaciones de pandas para evitar errores con \texttt{datetime64}.
		\item Comandos de Git para el trabajo con ramas (\texttt{main}, \texttt{develop}, \texttt{release}).
	\end{itemize}
	
	\section{Resultados}
	Al ejecutar el script principal:
	\begin{verbatim}
		python3 main.py
	\end{verbatim}
	
	Se obtiene:
	\begin{itemize}
		\item Archivo limpio: \texttt{Extract/Files/Nvidia\_clean.csv}
		\item Columnas originales más \texttt{Daily Change} y \texttt{Percent Change}
		\item 5872 filas procesadas correctamente
	\end{itemize}
	
	\section{Conclusiones}
	El proyecto demuestra cómo construir un flujo ETL modular y reproducible usando Python. El uso de ChatGPT facilitó la depuración y la optimización de rutas y transformaciones. La gestión de ramas en Git permite un desarrollo ordenado y preparación de releases.
	
\end{document}

